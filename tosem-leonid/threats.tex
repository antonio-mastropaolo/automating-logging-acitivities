% !TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Threats to Validity} \label{sec:threats}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Construct validity.} The building of our fine-tuning datasets rely on the assumption that the exploited code instances, as written by developers, represent the ``correct'' predictions that the models should generate. This is especially true for the classifier aimed at predicting whether log statements are needed. For example, the instances that we labeled as ``\emph{not needing log statements}'' are methods featuring $n \geq 1$ log statements from which we did not remove any log statement. Thus, we assume that these methods need exactly $n$ log statements (\ie the ones injected by the developers), not one more. This is a strong assumption, as confirmed by the examples in \figref{fig:no-need}. Still, using the code written by developers as oracle is a popular practice in DL for SE \cite{tufano2022using, Tufano:tosem2019, tufano-mutants, watson2020learning, tufano2022generating}.


\textbf{Internal validity.}  We performed the same hyperparameter tuning we proposed when introducing the T5 model to support code-related tasks \cite{mastropaolo2021studying}, while relying on the best architecture identified by Raffel \etal \cite{raffel2019exploring} for the other parameters. We acknowledge that additional tuning can result in improved performance.


\textbf{External validity.} Our research questions have been answered using a dataset being 3.6 times larger as compared to the dataset we originally used when proposing \cite{mastropaolo2022using}. Also, the new dataset is more variegated, featuring projects using different build systems (as compared to the Maven-only policy we relied in \cite{mastropaolo2022using}) and having dependencies towards different logging libraries (differently from the original Log4j-only policy we end up using in \cite{mastropaolo2022using}). Still, we do not claim generalizability of our findings for different populations of projects, especially those written in other programming languages.