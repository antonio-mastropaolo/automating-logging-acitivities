% !TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{table/comparison.tex}

The practice of injecting log statements in applications' code is widely adopted both in industry and open source projects \cite{}. Indeed, log statements are instrumental to support several software-related activities, including program comprehension and debugging \cite{}. Given its popularity, it comes without surprise the proliferation of libraries to support logging activities: just for Java some possible options are Log4j \cite{log4j}, JCL \cite{jcl}, slf4j \cite{slf4j}, and logback \cite{logback}.

While logging it is usually perceived as a good practice, it comes with its own drawbacks: Excessive logging could negatively impact performance and, if not carefully conceived, log statements can result in security issues such as providing access to user credentials or sensitive information. Also, researchers documented several bad practices that should be avoided while logging code \cite{Chen:icse2017,Li:icse2019}. In general, logging poses several challenges to software developers. First, they need to decide \emph{what to log}, by finding the right amount of log statements that are needed in the application without, however, flood it with useless log statements. Second, developers must \emph{log at the proper level}, namely select the proper log level for each entry (\eg info, warning, error). Third, log statements must be accompanied by \emph{meaningful and informative} log messages, that provide the right amount of information and can be easily understood. 

To support developers in these activities, researchers proposed techniques and tools automating specific aspects of logging, such as recommending (i) where/what to log \cite{yuan2010sherlog,jia2018smartlog,li2018studying,li2020shall}, and (ii) the right level to use for a given log statement \cite{yuan2012characterizing,oliner2012advances,li2017log,li2020qualitative,li2021deeplv}. Recently, Mastropaolo \etal \cite{mastropaolo2022using} presented LANCE, an approach built on top of a Text-To-Text-Transfer-Transformer (T5) deep learning (DL) model \cite{raffel2019exploring} trained to generate and inject a complete log statement in a Java method provided as input. The T5 model has been pre-trained on a set of $\sim$6.8M Java methods using the classic ``masked language modeling'' objective \cite{raffel2019exploring}. In the case of LANCE, this means that during pre-training the model is provided as input a Java method with 15\% of its tokens masked and it is expected to predict the masked tokens. Such a pre-training task provides T5 with knowledge about the language of interest (\ie Java). Once pre-trained, the model has been fine-tuned for the specific task of interest. In this case, the authors selected $\sim$62k Java methods and removed from them exactly one log statement asking the model to generate and inject it, thus deciding \emph{where} to log (\ie in which part of the method), which \emph{log level} to use, and \emph{what} to log (\ie generate a meaningful log message in natural language). LANCE is the first approach support developers in all these activities. The presented empirical evaluation showed that LANCE was able to correctly predict the appropriate location of a log statement and its level in $\sim$66\% of cases, while the approach struggled in predicting a meaningful log message, being successful in 15.2\% of test instances.

While LANCE represents a substantial step ahead in logging automation, it comes with some limitations. First, it assumes that only one log statement is needed in a Java method provided as input. This is due to the training procedure employed by the authors that asks the model to generate a single log statement. While such an assumption simplifies the addressed problem, it is not empirically supported, since \textcolor{red}{XX}\% of Java methods in our dataset makes use of more than one log statement. Second, while LANCE achieves good performance in predicting the log statement location and level, it showed substantial limitations when it comes to synthesizing meaningful natural language log messages. In this work we present \approach, an approach built on top of LANCE with the goal of partially addressing its two main limitations.

As LANCE, \approach exploit a T5 model that, however, has been trained and tested on a larger and more challenging dataset including instances requiring the injection of multiple log statements. Indeed, while there are no major differences when in comes to the pre-training procedure adopted in LANCE and \approach, in the fine-tuning phase we rely on a dataset of $\sim$244k Java methods, more than three times the number of methods on which LANCE has been trained on) requiring the injection of up to XX log statements (as compared to the single log statement injected by LANCE). Increasing the complexity of the problem is likely to result in a decrease of accuracy. However, \approach exploits a new fine-tuning strategy combining DL and Information Retrieval (IR) to boost the prediction accuracy when it comes to the most challenging sub-problem involved in log injection: the generation of a meaningful log message. To explain our fine-tuning training procedure let us indicate with $<$$m_i$, $LS=\{ls_1, ls_2, \dots, ls_n\}$$>$ a training instance in our dataset, with $m_i$ being a Java method from which we removed $n$ log statements and $LS$ being the set of removed statements the model is expected to generate. We identify in the training set the top-$k$ methods being most similar to $m_i$ and extract the set of log messages $M$ used in them. We use $M$ to augment our training instance, that becomes a triplet composed by $<$$m_i$, $LS=\{ls_1, ls_2, \dots, ls_n\}$, $M$$>$. The idea is that T5 can learn how to write a meaningful log message for $LS$ by looking at examples of log messages ($M$) used in methods similar to the one it is provided as input ($m_i$). While testing our approach on a previously unseen method $m_j$, we follow the same procedure by identifying the top-$k$ most similar methods in our training set.


The achieved results show that \textcolor{red}{TO CONTINUE}.