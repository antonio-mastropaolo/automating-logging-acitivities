{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GCS Auth"
      ],
      "metadata": {
        "id": "5aQA-PKv8TA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "uBr3EMo18LfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHq2Dgka_-v4"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output \n",
        "!pip install gcsfs\n",
        "!pip3 install t5==0.9.2\n",
        "!pip install -q tensorflow-text==2.8.0rc0\n",
        "!pip install sentencepiece \n",
        "clear_output()"
      ],
      "metadata": {
        "id": "CPe3gL1rjxgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LcsImcC_5rB"
      },
      "outputs": [],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "import sentencepiece as spm\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.app.flags.DEFINE_string ('f', '', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUbwjdsC_-Kt"
      },
      "outputs": [],
      "source": [
        "print(\"Setting up TPU...\")\n",
        "import tensorflow_gcs_config\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  TPU_ADDRESS = tpu.get_master()\n",
        "  print('Running on TPU:', TPU_ADDRESS)\n",
        "except ValueError:\n",
        "  raise BaseException(\n",
        "    'ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "tf.disable_v2_behavior()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paths"
      ],
      "metadata": {
        "id": "n6mKKdbuk7jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "representation = \"tokens\" #@param [\"ast\", \"tokens\"]\n",
        "task = \"masking\" #@param [\"masking\"]\n",
        "VOCAB_PREFIX = \"tokenizer\" #@param {type:\"string\"}\n",
        "tokenizer_source_file = f\"gs://lance2/tokenizer/{representation}/{VOCAB_PREFIX}.txt\"\n",
        "tokenizer_model_local_path = os.path.join(f\"/content/{VOCAB_PREFIX}.model\")\n",
        "tokenizer_vocab_local_path = os.path.join(f\"/content/{VOCAB_PREFIX}.vocab\")"
      ],
      "metadata": {
        "id": "KrhKlkjnk9Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXCG7-qKBKsc"
      },
      "source": [
        "# Training Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iLAOnrYBmxL"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 32000 #@param { type: \"integer\" }\n",
        "\n",
        "print(\"Training the tokenizer and building the vocabulary ...\")\n",
        "with tf.io.gfile.GFile(tokenizer_source_file, \"r\") as f:\n",
        "  spm.SentencePieceTrainer.train(sentence_iterator=f, \n",
        "                                 model_prefix=VOCAB_PREFIX,\n",
        "                                 pad_id=0, bos_id=-1, \n",
        "                                 eos_id=1, unk_id=2, \n",
        "                                 character_coverage=1.0, \n",
        "                                 vocab_size=VOCAB_SIZE)\n",
        "  print(f\"Training tokenizer finished, at: {tokenizer_model_local_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I5SXJwMBvWK"
      },
      "source": [
        "# Storing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UlBewhwBzuP"
      },
      "outputs": [],
      "source": [
        "tokenizer_model_path = f\"gs://lance2/tokenizer/{representation}/{VOCAB_PREFIX}.model\"\n",
        "tokenizer_vocab_path = f\"gs://lance2/tokenizer/{representation}/{VOCAB_PREFIX}.vocab\"\n",
        "\n",
        "## Store in GCS:\n",
        "!gsutil cp $tokenizer_model_local_path $tokenizer_model_path\n",
        "!gsutil cp $tokenizer_vocab_local_path $tokenizer_vocab_path\n",
        "\n",
        "print(\"Copying Finished.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NHq2Dgka_-v4"
      ],
      "machine_shape": "hm",
      "name": "Train-Tokenizer.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}