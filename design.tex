% !TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Study Design} \label{sec:design}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The \emph{goal} of our study is to evaluate the performance of \approach in automatically generating and injecting complete logging statements in Java methods in three different scenarios: single log injection, mutli-log injections, and whether or not add log statements. The context is represented by the datasets described in \secref{add}.

With our study, we aim at answering the following research questions (RQs):
\begin{itemize}

\item[\textbf{RQ$_1$:}]\textit{To what extent is \approach able to correctly inject a single complete logging statement in Java methods?} RQ$_1$ mirrors the study performed by Mastropaolo \etal~\cite{mastropaolo2022using} when presenting LANCE. In particular, we experiment \approach in the same scenario presented in \cite{mastropaolo2022using}: The injection of a single log statement in a given Java method. We compare the performance of \approach with that on LANCE when training and testing them on the same dataset. 
\smallskip

\item[\textbf{RQ$_2$:}]\textit{To what extent is \approach able to correctly inject multiple log statements when needed?} RQ$_1$ tests our approach in the most challenging scenario of generating from 1 to $n$ log statements as needed.

\item[\textbf{RQ$_3$:}]\textit{To what extent is \approach able to properly decide when to inject log statements?} RQ$_3$ analyzes the accuracy of \approach in predicting whether or not inject log statements, a problem that was oversaw in the work presenting LANCE.

\end{itemize}

\subsection{Data Collection and Analysis}

To answer RQ$_1$ and evaluate to what extent \approach overcomes the performance of the state-of-the-art LANCE, we run both approaches against the same dataset described in \secref{add}. Then, we assess the accuracy of the predictions generated by each model by computing quantitative metrics and complemented the evaluation of \approach with a qualitative analysis. We run LANCE and \approach against the largest dataset described in \secref{add} which includes SLF4 and Log4J log statements. 

As done by Mastropaolo \etal~\cite{mastropaolo2022using}, we use the code manually written by actual developers as an oracle to which compare the predictions of our approach. Using the manually written source code as an oracle is a common practice~\cite{MASTRO_17_30_40_41} used to estimate the ability of DL-based tools while mimicking human behavior.
Moreover, as Mastropaolo \etal~\cite{mastropaolo2022using} highlighted in their manuscript, a log statement prediction implies a three-fold challenge. In other words, a log statement is composed of three components: log position, log level, and log message; thus, the model needs to predict these three components in one shot. While guessing log position and level is a low-effort challenge, predicting the same terminology used by developers in their log messages is a non-trivial task due to the nature of the human language that can express concepts with different words.
For this reason, we consider three different metrics:
\begin{description}
	\item[correct predictions:] are all those predictions that simultaneously match the three components of a log statement (\ie it matches log position, level, and message) written by human developers;

	\item[partially correct predictions:] are all those predictions where the model is able to predict (i) one (\eg log level) or (ii) two (\eg log level and message) out of three components;

	\item[wrong predictions:] are the cases in which the model is not working correctly. We reserved a sample of these predictions for a further manual investigation that could shed light on the causes of this limitation.
\end{description}

To answer RQ$_2$ and evaluate to what extent \approach is able to correctly inject multiple log statements, we run \approach against an enriched dataset that contains Java methods including multiple log statements (\ie from 1 to $n$ different log statements). Also in this case, we collect three metrics including \emph{correct}, \emph{partially correct}, and \emph{wrong} predictions. Moreover, we sampled a {\color{red}{representative}} set of predictions and manually inspected them.


To answer RQ$_3$ and estimate the performance of \approach in suggesting whether a log statement is needed or not, we run \approach against the dataset described in \secref{add}. As done for RQ$_1$ and RQ$_2$, we assume that the code written by actual developers is the ground truth for evaluating this task~\cite{MASTRO_17_30_40_41}. In contrast to previous RQs, RQ$_3$ has a more simple evaluation due to its binary output: The given Java method needs or not a log statement. For this, we computed {\color{red}{precision}} and {\color{red}{recall}}.