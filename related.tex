% !TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work} \label{sec:related}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this work, we focus our discussion on studies aimed at (i) automating logging activities and (ii) combining deep learning and information retrieval to automate code-related activities. Due to space constraints, we point the reader to the literature review by Watson \etal~\cite{watsonSytematicLiterature2020} regarding the use of deep learning to automate different software engineering tasks.

\subsection{Automating Logging Activities}

Log analysis is a popular practice that support developers in software maintenance tasks such as software testing~\cite{chen2018automated,chen2019experience}, debugging~\cite{satyanarayanan1992transparent}, diagnosis~\cite{zhou2019latent,yuan2012improving}, and monitoring~\cite{hasselbring2020kieker,harty2021logging}. Nonetheless, augmenting source code with correct log statements is a non-trivial manual activity that require developer's experience~\cite{li2020qualitative,yuan2012characterizing}. For this reason, researchers started investigating how to support developers with automatic log injection.

Zhu \etal~\cite{zhu2015learning} conducted a pioneer work to design \textsc{LogAdvisor}. It is a tool to recommend where to inject log statements in the source code. The authors evaluated \textsc{LogAdvisor} on two Microsoft systems and two open-source projects. They reported an accuracy of 60\% when the tool is triggered to inject log statements on pieces of code without log statements.

Yao \etal~\cite{yao2018log4perf} have focused on a similar sub-problem: The proposed approach automatically suggests log statements in code developed to monitor the CPU usage of web-based systems. The results demonstrated a boost in such developers' activities.

Mizouchi \etal \cite{mizouchi2019padla}, moved ahead, and designed \textsc{PADLA}, an extension for the Apache Log4j framework to automatically change log levels of existent log statements. \textsc{PADLA} aims to adjust the log level to optimize the amount of the information logged at runtime and allow a responsive anomaly analysis.

Li \etal~\cite{li2020shall} introduced deep learning to generate logging location recommendations. Their tool reports a 80\% accuracy in suggesting logging locations using within-project training, with slightly worst results (67\%) in a cross-project setting.

Recently, Li \etal \cite{li2021deeplv} proposed also \textsc{DeepLV}. It is a tool based on deep learning to recommend the level of existing log statements in Java methods. \textsc{DeepLV} by aggregating both syntactic and semantic information of the source code showed its superiority with respect to the state-of-the-art tools.

Lastly, Mastropaolo \etal~\cite{mastropaolo2022using} introduced \textsc{LANCE}, a tool to inject log statements enriched with log levels and messages automatically. The proposed tool achieves outstanding performance when solving the first two tasks (65\% and 66\%, respectively, for log position and log levels) while hobbling on the most complex challenge: Generating natural language log messages. Moreover, their tool generates a single log message per method. With our study, we build on top of the above research, and experiment with an augmented model that outperforms \textsc{LANCE} by injecting multiple log statements. 

\subsection{Combining Deep Learning and IR to Automate Code Related Tasks}

Although deep learning showed great potential in solving various software engineering tasks~\cite{watsonSytematicLiterature2020}, it may still struggle with non-trivial challenges. For example, in a recent paper, Mastropaolo \etal~\cite{mastropaolo2022using} reported excellent performance in two of three tasks when employing DL for generating complete log statements. In particular, the proposed approach excels in predicting the log statement's position and verbosity but suffers from injecting non-trivial natural language messages. To overcome such a generative issue, researchers suggested supporting DL with IR techniques. For example, Lam \etal~\cite{LamBugLocalization2017} proposed to use IR alongside DL in the bug localization task. The authors overcome the linguistic mismatch between the two sets of vocabularies (\ie bug reports \emph{vs.} source code) by transforming the localization in a ranking problem solved though IR. The results reported that the two methods complement each other outperforming individual techniques. 
% Not sure about the following work, they do not use IR as we intend. It is only mentioned in the title.
%Similarly, Choetkiertikul \etal~\cite{choetkiertikul2018predicting} proposed to combine IR and DL to identify software components by the referenced open issues automatically.

An advanced solution comes from Yu \etal~\cite{yu2022automated}, which proposed to re-use available snippets of source code when the performance of their tool, \textsc{ATLAS}, drops. In other words, when the DL part of \textsc{ATLAS} fails, the tool selects an existent code assertion through IR-based technique and suggests it as a solution.

The key concept behind combining IR and DL is to fetch examples similar to the target from a pool of available data. To this aim, the Jaccard~\cite{tanimoto1958elementary} similarity is the most promising retrieval technique that offers a limited computation overhead. The Jaccard similarity returns a coefficient that estimate the similarity between two sets of data based on their overlapping and unique items.

